# Thought process for adding session saving and loading #

Here's a breakdown of the thought process for adding session saving and loading to the React frontend:

1.  **Understand the Goal:** The user wants to persist chat sessions locally in the browser so they can be reopened later. This involves storing session metadata (ID, name, timestamp, model info) and the associated message history.

2.  **Storage Mechanism:** Since this is a frontend-only feature (not syncing across devices/users yet), the browser's `localStorage` is the simplest and most suitable option. It allows storing key-value pairs as strings.

3.  **Data Structure for Storage:** How should we store multiple sessions?
    *   A single key holding a large JSON string representing *all* sessions seems feasible but could become cumbersome and potentially hit `localStorage` size limits if there are many long sessions.
    *   Storing each session under its own key seems more modular. We need a way to know *which* keys belong to our sessions. A naming convention (e.g., `rag_chat_session_`) is a good approach.
    *   We also need a way to list the available sessions easily. Storing a separate index key (e.g., `rag_chat_session_index`) containing a list of session IDs and their metadata (name, timestamp) would work well for populating a selection list without loading all message data initially.

4.  **Refining the Index:** The index key (`rag_chat_session_index`) should store an array of objects, each containing `id`, `name`, and `last_updated_at`. This allows sorting and displaying the list effectively.

5.  **Session Data Structure (Individual Key):** What data does each session key (`rag_chat_session_<id>`) need?
    *   `id`: The unique session ID (matches the key suffix).
    *   `name`: User-defined or default name.
    *   `created_at`: Timestamp (useful info, though maybe less critical than last updated).
    *   `last_updated_at`: Crucial for sorting and display.
    *   `llm_model_name`: Which model was used (fetch from backend status when saving).
    *   `backend_type`: Which backend was used.
    *   `generation_config`: The LLM parameters active *at the time of saving*.
    *   `messages`: The array of message objects `{ role, content, isError?, id? }`.

6.  **Frontend State Management (`App.jsx`):**
    *   We already have `messages` and `sessionId`.
    *   We need state to hold the list of *saved* sessions for the UI selector: `savedSessions` (array of index objects).
    *   We need state to track if the *current* chat is potentially different from the saved version (a "dirty" state) to prompt the user to save. `isChatDirty`.

7.  **Core Logic - Saving:**
    *   When should saving happen?
        *   Automatically on every message? Could be too frequent.
        *   Manually via a "Save Session" button? Gives user control. Let's start with manual.
        *   Automatically when switching sessions or closing the app? More complex (`beforeunload` event is unreliable). Manual save is simpler first step.
    *   **Save Function (`handleSaveSession`):**
        *   Needs the current `sessionId`, `messages`, and `llm_state` (fetched via API).
        *   Prompt the user for a session name (or use the existing one if saving over, or generate default). An `input` dialog or a dedicated input field could work. `prompt()` is simplest for now but not ideal UX.
        *   Fetch current LLM status (`/api/v1/models/status`) to get model name, backend type, and generation config *at the time of saving*.
        *   Construct the session data object (ID, name, timestamps, model info, messages).
        *   Save the session data object to `localStorage` using `localStorage.setItem('rag_chat_session_<id>', JSON.stringify(sessionData))`.
        *   Update the session index in `localStorage`:
            *   Read the existing index (`localStorage.getItem('rag_chat_session_index')`).
            *   Parse it (`JSON.parse`).
            *   Remove the old entry for this `sessionId` (if it exists).
            *   Add/update the entry with the new name and `last_updated_at`.
            *   Sort the index (e.g., by `last_updated_at` descending).
            *   Save the updated index back (`localStorage.setItem('rag_chat_session_index', JSON.stringify(updatedIndex))`).
        *   Update the `savedSessions` state in React to reflect the change in the UI list.
        *   Reset the `isChatDirty` flag.

8.  **Core Logic - Loading:**
    *   How to trigger loading? A dropdown/list of saved sessions.
    *   **Load Function (`handleLoadSession`):**
        *   Takes the `sessionId` to load as an argument.
        *   Prompt the user to save the *current* chat if `isChatDirty`. (Need to implement the dirty check).
        *   Read the session data from `localStorage` (`localStorage.getItem('rag_chat_session_<id>')`).
        *   Parse it (`JSON.parse`).
        *   Update the React state: `setMessages`, `setSessionId`, maybe even try to set the corresponding LLM model via API (though this could fail if the model/backend isn't available now). For simplicity, maybe just store the *loaded* model info but don't automatically try to activate it on the backend.
        *   Reset `isChatDirty`.

9.  **Core Logic - Deleting:**
    *   Needs a way to trigger (e.g., button next to each session in the list).
    *   **Delete Function (`handleDeleteSession`):**
        *   Takes `sessionId` to delete.
        *   Confirm with the user (`window.confirm`).
        *   Remove the item from `localStorage` (`localStorage.removeItem('rag_chat_session_<id>')`).
        *   Update the session index in `localStorage` (remove the entry).
        *   Update the `savedSessions` state in React.
        *   If the *currently active* session is deleted, potentially call `startNewChat`.

10. **Core Logic - Tracking Changes (`isChatDirty`):**
    *   When is the chat "dirty"? When `messages` change *after* loading a session or starting a new one.
    *   Set `isChatDirty = true` whenever `setMessages` is called *unless* it's during the initial load or `startNewChat`.
    *   Set `isChatDirty = false` after successfully saving or loading a session, or in `startNewChat`.
    *   We need to modify the `setMessages` calls in `handleSendMessage` and error handlers to also set `isChatDirty = true`.

11. **UI Components:**
    *   **`SessionManager`:** A new component to display the list of saved sessions, and include "Save Current" and potentially "Load" / "Delete" buttons.
    *   Modify `App.jsx`: Render `SessionManager`, pass necessary state and handlers (`savedSessions`, `handleLoadSession`, `handleSaveSession`, `handleDeleteSession`, `activeSessionId`).

12. **Refinements & Edge Cases:**
    *   Default session naming (`Session - date/time`).
    *   Error handling for `localStorage` operations (e.g., quota exceeded, JSON parsing errors).
    *   Handling the case where the LLM configuration stored with a session doesn't match the *current* backend state when loaded. Should the user be warned? Should we attempt to load the saved model? (Decided to just store the info for now, not automatically reload).
    *   Improve the "Save" prompt mechanism beyond `window.prompt`.

13. **Code Implementation:** Translate the logic above into React state, effects, handlers, and JSX, creating the `SessionManager` component and modifying `App.jsx`. Add corresponding CSS.
